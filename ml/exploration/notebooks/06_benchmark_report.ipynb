{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 06 â€“ Benchmark Report\n",
                "\n",
                "**Goal:** Aggregate all metrics from notebooks 01â€“05 and produce a final comparison report.\n",
                "\n",
                "**Outputs:**\n",
                "- Combined leaderboard table (Dice, IoU, HD95, volume accuracy, inference time)\n",
                "- Radar chart (multi-metric model comparison)\n",
                "- Longitudinal volume accuracy plot\n",
                "- Final recommendations for production pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys, os\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import nibabel as nib\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "NOTEBOOK_DIR = Path(os.getcwd())\n",
                "REPO_ROOT    = NOTEBOOK_DIR.parent.parent\n",
                "DATA_ROOT    = REPO_ROOT / 'P01'\n",
                "BRATS_DIR    = DATA_ROOT / 'BraTS'\n",
                "MASK_DIR     = DATA_ROOT / 'tumor segmentation'\n",
                "\n",
                "OUTPUTS_DIR  = NOTEBOOK_DIR.parent / 'outputs'\n",
                "REPORT_DIR   = OUTPUTS_DIR / '06_benchmark'\n",
                "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "sys.path.insert(0, str(NOTEBOOK_DIR.parent / 'utils'))\n",
                "from dicom_utils import get_p01_brats_paths, get_p01_mask_paths, load_nifti\n",
                "from metrics import BenchmarkTracker, compute_volume_from_nifti, dice_coefficient, iou_score, Timer\n",
                "from visualisation import plot_benchmark_bar, plot_benchmark_radar, plot_longitudinal_volume\n",
                "\n",
                "brats_paths = get_p01_brats_paths(BRATS_DIR)\n",
                "mask_paths  = get_p01_mask_paths(MASK_DIR)\n",
                "\n",
                "print('Loading metrics CSVs from previous notebooks...')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Load all CSV outputs from notebooks 02â€“05 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "all_dfs = []\n",
                "\n",
                "for csv_path in sorted(OUTPUTS_DIR.rglob('*_metrics.csv')):\n",
                "    try:\n",
                "        df = pd.read_csv(csv_path)\n",
                "        df['source_file'] = csv_path.name\n",
                "        all_dfs.append(df)\n",
                "        print(f'  Loaded: {csv_path.relative_to(OUTPUTS_DIR)} ({len(df)} rows)')\n",
                "    except Exception as e:\n",
                "        print(f'  Could not load {csv_path}: {e}')\n",
                "\n",
                "if all_dfs:\n",
                "    combined = pd.concat(all_dfs, ignore_index=True)\n",
                "    print(f'\\nTotal records: {len(combined)}')\n",
                "else:\n",
                "    print('No metrics CSV files found. Run notebooks 02-05 first.')\n",
                "    combined = pd.DataFrame(columns=['model','timepoint','dice','iou','volume_pred_cm3','inference_s','vram_gb','hd95_mm'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Re-compute all metrics from saved prediction NIfTIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "fresh_tracker = BenchmarkTracker()\n",
                "\n",
                "MODEL_DIRS = {\n",
                "    'nnunet':        OUTPUTS_DIR / '02_nnunet' / 'predictions',\n",
                "    'medgemma':      OUTPUTS_DIR / '03_medgemma',\n",
                "    'llava_med':     OUTPUTS_DIR / '03_medgemma',\n",
                "    'sam3__box':     OUTPUTS_DIR / '04_sam',\n",
                "    'sam2__box':     OUTPUTS_DIR / '04_sam',\n",
                "    'sam__box_stub': OUTPUTS_DIR / '04_sam',\n",
                "    'majority_vote': OUTPUTS_DIR / '05_ensemble',\n",
                "    'staple':        OUTPUTS_DIR / '05_ensemble',\n",
                "    'union':         OUTPUTS_DIR / '05_ensemble',\n",
                "    'intersection':  OUTPUTS_DIR / '05_ensemble',\n",
                "}\n",
                "\n",
                "PRED_PATTERNS = {\n",
                "    'nnunet':        lambda tp: f'P01_{tp}_pred.nii.gz',\n",
                "    'medgemma':      lambda tp: f'medgemma_{tp}_pred.nii.gz',\n",
                "    'llava_med':     lambda tp: f'llava_med_{tp}_pred.nii.gz',\n",
                "    'sam3__box':     lambda tp: f'sam3_{tp}_box_pred.nii.gz',\n",
                "    'sam2__box':     lambda tp: f'sam2_{tp}_box_pred.nii.gz',\n",
                "    'sam__box_stub': lambda tp: f'sam_{tp}_box_pred.nii.gz',\n",
                "    'majority_vote': lambda tp: f'majority_vote_{tp}.nii.gz',\n",
                "    'staple':        lambda tp: f'staple_{tp}.nii.gz',\n",
                "    'union':         lambda tp: f'union_{tp}.nii.gz',\n",
                "    'intersection':  lambda tp: f'intersection_{tp}.nii.gz',\n",
                "}\n",
                "\n",
                "timepoints = list(brats_paths.keys())\n",
                "\n",
                "for model_name, pred_dir in MODEL_DIRS.items():\n",
                "    for tp in timepoints:\n",
                "        gt_path = mask_paths.get(tp)\n",
                "        if not gt_path:\n",
                "            continue\n",
                "        pred_filename = PRED_PATTERNS[model_name](tp)\n",
                "        pred_path = pred_dir / pred_filename\n",
                "\n",
                "        if not pred_path.exists():\n",
                "            fresh_tracker.add_mock(model=model_name, timepoint=tp)\n",
                "            continue\n",
                "\n",
                "        gt_arr, _, _   = load_nifti(gt_path)\n",
                "        pred_arr, _, _ = load_nifti(str(pred_path))\n",
                "        spacing        = tuple(float(s) for s in nib.load(gt_path).header.get_zooms()[:3])\n",
                "\n",
                "        fresh_tracker.add(model=model_name, timepoint=tp,\n",
                "                          pred=pred_arr, gt=gt_arr, spacing=spacing)\n",
                "\n",
                "fresh_df = fresh_tracker.to_dataframe()\n",
                "print(f'Fresh computation: {len(fresh_df)} records')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Merge and deduplicate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "all_data = pd.concat([combined, fresh_df], ignore_index=True)\n",
                "all_data = all_data.drop_duplicates(subset=['model', 'timepoint'], keep='last')\n",
                "all_data = all_data[all_data['dice'].notna()].copy()\n",
                "\n",
                "print(f'Total valid records: {len(all_data)}')\n",
                "print(all_data[['model','timepoint','dice','iou','volume_pred_cm3','inference_s']].to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "leaderboard = (\n",
                "    all_data.groupby('model')[['dice','iou','hd95_mm','volume_pred_cm3','inference_s']]\n",
                "    .mean().round(4)\n",
                "    .sort_values('dice', ascending=False)\n",
                ")\n",
                "\n",
                "gt_volumes   = {tp: compute_volume_from_nifti(p) for tp, p in mask_paths.items()}\n",
                "mean_gt_vol  = np.mean(list(gt_volumes.values()))\n",
                "leaderboard['vol_error_cm3'] = (leaderboard['volume_pred_cm3'] - mean_gt_vol).abs().round(4)\n",
                "leaderboard['vol_error_pct'] = ((leaderboard['vol_error_cm3'] / (mean_gt_vol+1e-6))*100).round(2)\n",
                "\n",
                "print('=== FINAL LEADERBOARD ===')\n",
                "print(leaderboard.to_string())\n",
                "leaderboard.to_csv(REPORT_DIR / 'final_leaderboard.csv')\n",
                "all_data.to_csv(REPORT_DIR / 'all_metrics_raw.csv', index=False)\n",
                "print('\\nSaved: outputs/06_benchmark/final_leaderboard.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Dice bar chart â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "lb = leaderboard.reset_index()\n",
                "fig = plot_benchmark_bar(lb, metric='dice', title='Segmentation Dice Score â€“ All Models & Strategies')\n",
                "plt.savefig(REPORT_DIR / 'dice_leaderboard.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Radar chart â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "radar_metrics = [m for m in ['dice','iou','inference_s','hd95_mm']\n",
                "                 if m in lb.columns and lb[m].notna().any()]\n",
                "if len(radar_metrics) >= 3:\n",
                "    fig = plot_benchmark_radar(lb, metrics=radar_metrics)\n",
                "    plt.savefig(REPORT_DIR / 'radar_chart.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "else:\n",
                "    print('Not enough metrics for radar chart.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Longitudinal volume accuracy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "long_volumes = {'Ground Truth': gt_volumes}\n",
                "for model_name in all_data['model'].unique():\n",
                "    sub = all_data[all_data['model'] == model_name]\n",
                "    tp_vol = dict(zip(sub['timepoint'], sub['volume_pred_cm3']))\n",
                "    if any(v is not None for v in tp_vol.values()):\n",
                "        long_volumes[model_name] = tp_vol\n",
                "\n",
                "tp_order = list(brats_paths.keys())\n",
                "fig = plot_longitudinal_volume(long_volumes, timepoint_labels=tp_order)\n",
                "plt.savefig(REPORT_DIR / 'longitudinal_volumes.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Preprocessing summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "preproc_csv = OUTPUTS_DIR / '01_preprocessing' / 'preprocessing_summary.csv'\n",
                "if preproc_csv.exists():\n",
                "    preproc_df = pd.read_csv(preproc_csv)\n",
                "    print('=== Preprocessing Comparison ===')\n",
                "    print(preproc_df.to_string(index=False))\n",
                "    preproc_df.to_csv(REPORT_DIR / 'preprocessing_summary.csv', index=False)\n",
                "else:\n",
                "    print('Preprocessing summary not available - run notebook 01 first.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Final recommendations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "print('=' * 60)\n",
                "print('FINAL RECOMMENDATIONS â€“ OncoFlow Phase 4')\n",
                "print('=' * 60)\n",
                "\n",
                "if len(leaderboard) > 0:\n",
                "    ensemble_models = ['majority_vote','staple','union','intersection']\n",
                "    best_single = leaderboard[\n",
                "        ~leaderboard.index.isin(ensemble_models + ['weighted_oracle'])\n",
                "    ].index[0] if len(leaderboard) > 0 else 'N/A'\n",
                "    best_ensemble = leaderboard[\n",
                "        leaderboard.index.isin(ensemble_models)\n",
                "    ].index[0] if any(leaderboard.index.isin(ensemble_models)) else 'majority_vote'\n",
                "\n",
                "    print(f'\\nBest single model : {best_single}')\n",
                "    print(f'Best ensemble     : {best_ensemble}')\n",
                "\n",
                "recs = {\n",
                "    'Processing pipeline':  'SimpleITK (A1) for speed; dcm2niix (A2) for clinical compatibility',\n",
                "    'nnU-Net role':         'Primary volumetric segmenter â€” train on BraTS 2024',\n",
                "    'MedGemma role':        'RAG / report text generation (NOT segmentation)',\n",
                "    'SAM3 role':            'Interactive refinement in UI + box-prompted ensemble member',\n",
                "    'Ensemble strategy':    'Majority vote (default); STAPLE with calibration data',\n",
                "    'Agreement threshold':  '>= 0.90 auto-report | 0.75-0.89 flag | < 0.75 manual',\n",
                "}\n",
                "print('\\n--- Recommendations ---')\n",
                "for k, v in recs.items():\n",
                "    print(f'  {k:25s}: {v}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Save HTML report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "import base64, shutil\n",
                "\n",
                "# Consolidate all PNGs into report dir\n",
                "for src in OUTPUTS_DIR.rglob('*.png'):\n",
                "    dst = REPORT_DIR / src.name\n",
                "    if dst != src:\n",
                "        shutil.copy(src, dst)\n",
                "\n",
                "html_sections = ['<html><head><title>OncoFlow Phase 4 Report</title><style>body{font-family:sans-serif;max-width:1200px;margin:auto;padding:20px} table{border-collapse:collapse;width:100%} th,td{border:1px solid #ddd;padding:8px;text-align:center} th{background:#4a7fc1;color:white}</style></head><body>']\n",
                "html_sections.append('<h1>OncoFlow Phase 4 â€“ ML Exploration Report</h1>')\n",
                "html_sections.append('<p><b>Patient:</b> P01 | <b>Timepoints:</b> baseline, fu1, fu2, fu3, fu4</p>')\n",
                "html_sections.append('<h2>Leaderboard</h2>')\n",
                "html_sections.append(leaderboard.to_html(float_format='%.4f') if len(leaderboard) > 0 else '<p>No data â€” run notebooks 02-05 first</p>')\n",
                "\n",
                "for img_path in sorted(REPORT_DIR.glob('*.png')):\n",
                "    with open(img_path, 'rb') as f:\n",
                "        b64 = base64.b64encode(f.read()).decode()\n",
                "    html_sections.append(f'<h2>{img_path.stem.replace(\"_\", \" \").title()}</h2>')\n",
                "    html_sections.append(f'<img src=\"data:image/png;base64,{b64}\" width=\"900\"/>')\n",
                "\n",
                "html_sections.append('</body></html>')\n",
                "report_path = REPORT_DIR / 'exploration_report.html'\n",
                "report_path.write_text('\\n'.join(html_sections))\n",
                "print(f'Report saved: {report_path}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‹ Summary\n",
                "\n",
                "| Dimension | Decision |\n",
                "|-----------|----------|\n",
                "| **Processing pipeline** | SimpleITK (A1) for production speed; A3 (N4+zscore) for training data |\n",
                "| **Segmentation** | nnU-Net v2 (primary) + SAM3 box-prompted (secondary) |\n",
                "| **VLM** | MedGemma-1.5 for clinical summary generation, NOT segmentation |\n",
                "| **Ensemble** | Majority vote; upgrade to STAPLE with labelled data |\n",
                "| **Agreement flagging** | â‰¥0.90 auto / 0.75â€“0.89 review / <0.75 manual |\n",
                "\n",
                "**Next steps (Phase 5â€“7):**\n",
                "1. Fine-tune nnU-Net on internal data\n",
                "2. Integrate MedGemma into RAG pipeline\n",
                "3. Wire SAM3 interactive mode into frontend"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}