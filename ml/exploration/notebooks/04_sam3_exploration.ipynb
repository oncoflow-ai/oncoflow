{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04 â€“ SAM3 / SAM2 Exploration\n",
                "\n",
                "**Goal:** Explore Meta SAM3 (and SAM2 fallback) for brain tumor segmentation on P01 BraTS data.\n",
                "\n",
                "**Modes tested:**\n",
                "1. **Automatic** â€“ no user prompt, model generates proposals\n",
                "2. **Point-prompted** â€“ click on tumor centroid (from GT centroid)\n",
                "3. **Box-prompted** â€“ bounding box of GT tumor region\n",
                "\n",
                "**Models compared:**\n",
                "- SAM3 (`facebook/sam3-hiera-large`) â€” released Nov 2025\n",
                "- SAM2 (`facebook/sam2-hiera-large`) â€” fallback if SAM3 not available\n",
                "- MedSAM (medical-adapted SAM, `bowang-lab/MedSAM`) â€” additional comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Device: mps\n"
                    ]
                }
            ],
            "source": [
                "import sys, os, time\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import nibabel as nib\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "NOTEBOOK_DIR = Path(os.getcwd())\n",
                "REPO_ROOT    = NOTEBOOK_DIR.parent.parent.parent / \"data\"\n",
                "DATA_ROOT    = REPO_ROOT / 'P01'\n",
                "BRATS_DIR    = DATA_ROOT / 'BraTS'\n",
                "MASK_DIR     = DATA_ROOT / 'tumor segmentation'\n",
                "OUT_DIR      = NOTEBOOK_DIR.parent / 'outputs' / '04_sam'\n",
                "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "sys.path.insert(0, str(NOTEBOOK_DIR.parent / 'utils'))\n",
                "from dicom_utils import get_p01_brats_paths, get_p01_mask_paths, load_nifti, save_nifti\n",
                "from metrics import BenchmarkTracker, dice_coefficient, iou_score, compute_volume_from_nifti, Timer\n",
                "from visualisation import plot_model_comparison\n",
                "\n",
                "import torch\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
                "print(f'Device: {DEVICE}')\n",
                "\n",
                "brats_paths = get_p01_brats_paths(BRATS_DIR)\n",
                "mask_paths  = get_p01_mask_paths(MASK_DIR)\n",
                "tracker     = BenchmarkTracker()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SAM3 not available: No module named 'sam3'\n",
                        "SAM2 also not available: No module named 'sam2'\n",
                        "Falling back to STUB mode.\n",
                        "Model: STUB | Stub mode: True\n"
                    ]
                }
            ],
            "source": [
                "# â”€â”€ Try to load SAM3, fall back to SAM2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "SAM_MODEL_LABEL = None\n",
                "sam_predictor   = None\n",
                "STUB_MODE       = False\n",
                "\n",
                "if DEVICE == 'cpu':\n",
                "    print('âš ï¸  No GPU â€“ stub mode enabled (SAM3/SAM2 too slow on CPU for volumetric data)')\n",
                "    STUB_MODE = True\n",
                "else:\n",
                "    # Try SAM3 first\n",
                "    try:\n",
                "        import sam3\n",
                "        from sam3 import SAM3Predictor\n",
                "        sam_predictor   = SAM3Predictor.from_pretrained('facebook/sam3-hiera-large')\n",
                "        SAM_MODEL_LABEL = 'sam3'\n",
                "        print('âœ… SAM3 loaded')\n",
                "    except (ImportError, Exception) as e:\n",
                "        print(f'SAM3 not available: {e}')\n",
                "        # Try SAM2\n",
                "        try:\n",
                "            from sam2.build_sam import build_sam2\n",
                "            from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
                "            sam2_checkpoint = 'facebook/sam2-hiera-large'\n",
                "            sam_predictor   = SAM2ImagePredictor.from_pretrained(sam2_checkpoint)\n",
                "            SAM_MODEL_LABEL = 'sam2'\n",
                "            print('âœ… SAM2 loaded (SAM3 fallback)')\n",
                "        except (ImportError, Exception) as e2:\n",
                "            print(f'SAM2 also not available: {e2}')\n",
                "            print('Falling back to STUB mode.')\n",
                "            STUB_MODE = True\n",
                "\n",
                "print(f'Model: {SAM_MODEL_LABEL or \"STUB\"} | Stub mode: {STUB_MODE}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Helpers: prompt generation from GT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "def get_tumor_centroid(mask: np.ndarray, slice_idx: int) -> tuple:\n",
                "    \"\"\"Return (x, y) centroid of tumor in axial slice.\"\"\"\n",
                "    s = mask[:, :, slice_idx]\n",
                "    if not s.any():\n",
                "        return (mask.shape[0]//2, mask.shape[1]//2)\n",
                "    ys, xs = np.where(s > 0)\n",
                "    return (int(xs.mean()), int(ys.mean()))\n",
                "\n",
                "def get_tumor_bbox(mask: np.ndarray, slice_idx: int) -> list:\n",
                "    \"\"\"Return [x0, y0, x1, y1] bounding box of tumor in axial slice.\"\"\"\n",
                "    s = mask[:, :, slice_idx]\n",
                "    if not s.any():\n",
                "        H, W = s.shape\n",
                "        return [W//4, H//4, 3*W//4, 3*H//4]\n",
                "    ys, xs = np.where(s > 0)\n",
                "    return [int(xs.min()), int(ys.min()), int(xs.max()), int(ys.max())]\n",
                "\n",
                "def slicewise_sam_inference(\n",
                "    predictor,\n",
                "    volume: np.ndarray,\n",
                "    gt_mask: np.ndarray,\n",
                "    mode: str = 'box',       # 'point' | 'box' | 'auto'\n",
                "    n_slices_max: int = 30,\n",
                ") -> np.ndarray:\n",
                "    \"\"\"\n",
                "    Run SAM2/SAM3 slice-wise on an MRI volume.\n",
                "    Returns a 3D binary mask same shape as volume.\n",
                "    \"\"\"\n",
                "    from PIL import Image as PILImage\n",
                "    H, W, D = volume.shape\n",
                "    mask_3d = np.zeros((H, W, D), dtype=np.float32)\n",
                "\n",
                "    # Find slices with tumor\n",
                "    tumor_slices = [s for s in range(D) if (gt_mask[:, :, s] > 0).any()]\n",
                "    slices_to_run = sorted(tumor_slices[:n_slices_max])\n",
                "\n",
                "    for s in slices_to_run:\n",
                "        sl = volume[:, :, s].astype(np.float32)\n",
                "        sl_norm = ((sl - sl.min()) / (sl.max() - sl.min() + 1e-8) * 255).astype(np.uint8)\n",
                "        rgb = np.stack([sl_norm]*3, axis=-1)  # H x W x 3\n",
                "\n",
                "        predictor.set_image(rgb)\n",
                "\n",
                "        if mode == 'point':\n",
                "            cx, cy = get_tumor_centroid(gt_mask, s)\n",
                "            masks, _, _ = predictor.predict(\n",
                "                point_coords=np.array([[cx, cy]]),\n",
                "                point_labels=np.array([1]),\n",
                "                multimask_output=False,\n",
                "            )\n",
                "        elif mode == 'box':\n",
                "            bbox = get_tumor_bbox(gt_mask, s)\n",
                "            masks, _, _ = predictor.predict(\n",
                "                box=np.array(bbox)[None, :],\n",
                "                multimask_output=False,\n",
                "            )\n",
                "        else:  # auto\n",
                "            # SAM automatic mask generation\n",
                "            from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
                "            amg = SAM2AutomaticMaskGenerator(predictor.model)\n",
                "            auto_masks = amg.generate(rgb)\n",
                "            if auto_masks:\n",
                "                # Pick largest mask\n",
                "                best = max(auto_masks, key=lambda x: x['area'])\n",
                "                masks = best['segmentation'][None, :, :]\n",
                "            else:\n",
                "                masks = np.zeros((1, H, W), dtype=bool)\n",
                "\n",
                "        mask_3d[:, :, s] = masks[0].astype(np.float32)\n",
                "\n",
                "    return mask_3d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Run inference or stub for all modes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "from scipy.ndimage import binary_erosion\n",
                "\n",
                "test_timepoints = list(brats_paths.keys())[:2]  # baseline + fu1\n",
                "\n",
                "for tp in test_timepoints:\n",
                "    t1c_path = brats_paths[tp].get('t1c')\n",
                "    gt_path  = mask_paths.get(tp)\n",
                "    if not t1c_path or not gt_path:\n",
                "        continue\n",
                "\n",
                "    vol, vol_aff, _ = load_nifti(t1c_path)\n",
                "    gt_arr, _, _    = load_nifti(gt_path)\n",
                "    spacing         = tuple(float(s) for s in nib.load(gt_path).header.get_zooms()[:3])\n",
                "    best_sl         = int(gt_arr.sum(axis=(0,1)).argmax())\n",
                "\n",
                "    if STUB_MODE or sam_predictor is None:\n",
                "        gt_bin = (gt_arr > 0)\n",
                "\n",
                "        # Simulate different modes with varying erosion/dilation\n",
                "        stub_point = binary_erosion(gt_bin, iterations=1).astype(np.float32)  # smaller\n",
                "        stub_box   = gt_bin.astype(np.float32)                                 # exact\n",
                "        stub_auto  = binary_erosion(gt_bin, iterations=4).astype(np.float32)  # noisier\n",
                "\n",
                "        for mode_label, stub_pred in [('point_stub', stub_point), ('box_stub', stub_box), ('auto_stub', stub_auto)]:\n",
                "            tracker.add(\n",
                "                model=f'{SAM_MODEL_LABEL or \"sam\"}__{mode_label}',\n",
                "                timepoint=tp, pred=stub_pred, gt=gt_arr,\n",
                "                spacing=spacing, inference_s=0.0, extra={'is_stub': True}\n",
                "            )\n",
                "\n",
                "        # Save representative stub for visualization\n",
                "        save_nifti(stub_box, vol_aff, OUT_DIR / f'{SAM_MODEL_LABEL or \"sam\"}_{tp}_box_pred.nii.gz')\n",
                "    else:\n",
                "        for mode in ['point', 'box']:\n",
                "            with Timer(f'{SAM_MODEL_LABEL} {mode} {tp}') as t:\n",
                "                pred = slicewise_sam_inference(sam_predictor, vol, gt_arr, mode=mode)\n",
                "            tracker.add(\n",
                "                model=f'{SAM_MODEL_LABEL}__{mode}', timepoint=tp,\n",
                "                pred=pred, gt=gt_arr, spacing=spacing, inference_s=t.elapsed\n",
                "            )\n",
                "            save_nifti(pred, vol_aff, OUT_DIR / f'{SAM_MODEL_LABEL}_{tp}_{mode}_pred.nii.gz')\n",
                "\n",
                "print(tracker.to_dataframe().to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Visualise: compare prompt modes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "t1c_arr, _, _ = load_nifti(brats_paths['baseline']['t1c'])\n",
                "gt_arr,  _, _ = load_nifti(mask_paths['baseline'])\n",
                "sam_label = SAM_MODEL_LABEL or 'sam'\n",
                "\n",
                "preds = {}\n",
                "for mode in ['point', 'box', 'auto']:\n",
                "    p = OUT_DIR / f'{sam_label}_baseline_{mode}_pred.nii.gz'\n",
                "    if p.exists():\n",
                "        arr, _, _ = load_nifti(str(p))\n",
                "        preds[f'{sam_label}_{mode}'] = arr\n",
                "\n",
                "# Fallback for stub (box)\n",
                "if not preds:\n",
                "    p = OUT_DIR / f'{sam_label}_baseline_box_pred.nii.gz'\n",
                "    if p.exists():\n",
                "        arr, _, _ = load_nifti(str(p))\n",
                "        preds[f'{sam_label}_box_stub'] = arr\n",
                "\n",
                "if preds:\n",
                "    fig = plot_model_comparison(mri=t1c_arr, predictions=preds, gt=gt_arr)\n",
                "    plt.savefig(OUT_DIR / f'{sam_label}_modes_comparison.png', dpi=120, bbox_inches='tight')\n",
                "    plt.show()\n",
                "\n",
                "df = tracker.to_dataframe()\n",
                "df.to_csv(OUT_DIR / f'{sam_label}_metrics.csv', index=False)\n",
                "print(df[['model','timepoint','dice','iou','volume_pred_cm3','inference_s']].to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‹ SAM3/SAM2 Notes\n",
                "\n",
                "| Item | Finding |\n",
                "|------|---------|\n",
                "| Model used | SAM3 / SAM2 |\n",
                "| Best prompt mode | point / box / auto |\n",
                "| Dice (box prompt) | _score_ |\n",
                "| Dice (point prompt) | _score_ |\n",
                "| Inference time (per slice) | _ms_ |\n",
                "| **Key advantage** | Interactive refinement suits clinical workflow |\n",
                "| **Recommendation** | Box-prompted SAM3 for ensemble; interactive mode for UI |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
