{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05 ‚Äì Ensemble Strategies\n",
                "\n",
                "**Goal:** Fuse the three model predictions and compare ensemble strategies.\n",
                "\n",
                "| Strategy | Description |\n",
                "|----------|-------------|\n",
                "| **Majority vote** | ‚â•2/3 models agree per voxel |\n",
                "| **Union** | Any model predicts tumor |\n",
                "| **Intersection** | All models agree |\n",
                "| **STAPLE** | EM-based probabilistic fusion (SimpleITK) |\n",
                "| **Weighted avg** | Weight by Dice vs GT (oracle-weighted) |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys, os\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import nibabel as nib\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import SimpleITK as sitk\n",
                "\n",
                "NOTEBOOK_DIR = Path(os.getcwd())\n",
                "REPO_ROOT    = NOTEBOOK_DIR.parent.parent\n",
                "DATA_ROOT    = REPO_ROOT / 'P01'\n",
                "BRATS_DIR    = DATA_ROOT / 'BraTS'\n",
                "MASK_DIR     = DATA_ROOT / 'tumor segmentation'\n",
                "OUT_DIR      = NOTEBOOK_DIR.parent / 'outputs' / '05_ensemble'\n",
                "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Output dirs of previous notebooks\n",
                "NNUNET_OUT  = NOTEBOOK_DIR.parent / 'outputs' / '02_nnunet' / 'predictions'\n",
                "VLM_OUT     = NOTEBOOK_DIR.parent / 'outputs' / '03_medgemma'\n",
                "SAM_OUT     = NOTEBOOK_DIR.parent / 'outputs' / '04_sam'\n",
                "\n",
                "sys.path.insert(0, str(NOTEBOOK_DIR.parent / 'utils'))\n",
                "from dicom_utils import get_p01_brats_paths, get_p01_mask_paths, load_nifti, save_nifti\n",
                "from metrics import BenchmarkTracker, dice_coefficient, iou_score, pairwise_dice_matrix, agreement_score\n",
                "from visualisation import plot_model_comparison, plot_benchmark_bar\n",
                "\n",
                "brats_paths = get_p01_brats_paths(BRATS_DIR)\n",
                "mask_paths  = get_p01_mask_paths(MASK_DIR)\n",
                "tracker     = BenchmarkTracker()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚îÄ‚îÄ Ensemble strategy functions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "\n",
                "def majority_vote(masks: dict) -> np.ndarray:\n",
                "    \"\"\"‚â• 50% of models predict tumor per voxel.\"\"\"\n",
                "    stack = np.stack([m > 0.5 for m in masks.values()], axis=0)  # (N, H, W, D)\n",
                "    return (stack.sum(axis=0) >= len(masks) / 2).astype(np.float32)\n",
                "\n",
                "def union_vote(masks: dict) -> np.ndarray:\n",
                "    \"\"\"Any model predicts tumor.\"\"\"\n",
                "    result = np.zeros_like(next(iter(masks.values())), dtype=np.float32)\n",
                "    for m in masks.values():\n",
                "        result = np.maximum(result, (m > 0.5).astype(np.float32))\n",
                "    return result\n",
                "\n",
                "def intersection_vote(masks: dict) -> np.ndarray:\n",
                "    \"\"\"All models agree on tumor.\"\"\"\n",
                "    result = np.ones_like(next(iter(masks.values())), dtype=np.float32)\n",
                "    for m in masks.values():\n",
                "        result = np.minimum(result, (m > 0.5).astype(np.float32))\n",
                "    return result\n",
                "\n",
                "def staple_fusion(masks: dict) -> np.ndarray:\n",
                "    \"\"\"\n",
                "    STAPLE algorithm via SimpleITK.\n",
                "    Returns a probabilistic (soft) mask, thresholded at 0.5.\n",
                "    \"\"\"\n",
                "    sitk_masks = [sitk.GetImageFromArray((m > 0.5).astype(np.uint8)) for m in masks.values()]\n",
                "    staple_filter = sitk.STAPLEImageFilter()\n",
                "    staple_filter.SetForegroundValue(1)\n",
                "    result_sitk = staple_filter.Execute(sitk_masks)\n",
                "    prob = sitk.GetArrayFromImage(result_sitk)\n",
                "    return (prob > 0.5).astype(np.float32)\n",
                "\n",
                "def weighted_avg(masks: dict, gt: np.ndarray) -> np.ndarray:\n",
                "    \"\"\"\n",
                "    Oracle-weighted average: weight each model by its Dice vs GT.\n",
                "    NOTE: Uses GT so this is an oracle (upper-bound) strategy only.\n",
                "    \"\"\"\n",
                "    weights = {name: dice_coefficient(mask, gt) for name, mask in masks.items()}\n",
                "    total_w = sum(weights.values()) + 1e-8\n",
                "    result = np.zeros_like(next(iter(masks.values())), dtype=np.float32)\n",
                "    for name, mask in masks.items():\n",
                "        result += (weights[name] / total_w) * (mask > 0.5).astype(np.float32)\n",
                "    return (result > 0.5).astype(np.float32)\n",
                "\n",
                "print('Ensemble functions defined.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚îÄ‚îÄ Load predictions from previous notebooks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "# We try to load real predictions; fall back to GT-derived stubs if unavailable.\n",
                "\n",
                "def load_pred_or_stub(path: Path, gt_arr: np.ndarray, gt_aff, erosion: int = 0) -> np.ndarray:\n",
                "    from scipy.ndimage import binary_erosion, binary_dilation\n",
                "    if path.exists():\n",
                "        arr, _, _ = load_nifti(str(path))\n",
                "        return arr\n",
                "    # Stub: perturb GT to simulate model output\n",
                "    gt_bin = gt_arr > 0\n",
                "    if erosion > 0:\n",
                "        stub = binary_erosion(gt_bin, iterations=erosion).astype(np.float32)\n",
                "    else:\n",
                "        stub = binary_dilation(gt_bin, iterations=abs(erosion)).astype(np.float32)\n",
                "    return stub\n",
                "\n",
                "all_results = {}\n",
                "\n",
                "for tp in list(brats_paths.keys())[:3]:  # baseline, fu1, fu2\n",
                "    gt_arr, gt_aff, _ = load_nifti(mask_paths[tp])\n",
                "    spacing = tuple(float(s) for s in nib.load(mask_paths[tp]).header.get_zooms()[:3])\n",
                "\n",
                "    # Load (or stub) each model\n",
                "    nnunet = load_pred_or_stub(NNUNET_OUT / f'P01_{tp}_pred.nii.gz', gt_arr, gt_aff, erosion=2)\n",
                "\n",
                "    # VLM ‚Äì try medgemma first, then llava_med, then stub\n",
                "    vlm = None\n",
                "    for vlm_name in ['medgemma', 'llava_med']:\n",
                "        p = VLM_OUT / f'{vlm_name}_{tp}_pred.nii.gz'\n",
                "        if p.exists():\n",
                "            vlm, _ , _ = load_nifti(str(p))\n",
                "            break\n",
                "    if vlm is None:\n",
                "        from scipy.ndimage import binary_dilation\n",
                "        vlm = binary_dilation((gt_arr > 0), iterations=3).astype(np.float32)\n",
                "\n",
                "    # SAM\n",
                "    sam = None\n",
                "    for sam_name in ['sam3', 'sam2', 'sam']:\n",
                "        p = SAM_OUT / f'{sam_name}_{tp}_box_pred.nii.gz'\n",
                "        if p.exists():\n",
                "            sam, _, _ = load_nifti(str(p))\n",
                "            break\n",
                "    if sam is None:\n",
                "        sam = (gt_arr > 0).astype(np.float32)\n",
                "\n",
                "    masks = {'nnunet': nnunet, 'vlm': vlm, 'sam': sam}\n",
                "    all_results[tp] = {'masks': masks, 'gt': gt_arr, 'spacing': spacing, 'affine': gt_aff}\n",
                "\n",
                "print(f'Loaded predictions for {list(all_results.keys())}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚îÄ‚îÄ Run all ensemble strategies ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "strategy_names = ['majority_vote', 'union', 'intersection']\n",
                "strategy_fns   = [majority_vote, union_vote, intersection_vote]\n",
                "\n",
                "# Try STAPLE\n",
                "try:\n",
                "    import SimpleITK as sitk\n",
                "    strategy_names.append('staple')\n",
                "    strategy_fns.append(staple_fusion)\n",
                "    print('STAPLE available')\n",
                "except Exception as e:\n",
                "    print(f'STAPLE skipped: {e}')\n",
                "\n",
                "for tp, data in all_results.items():\n",
                "    masks  = data['masks']\n",
                "    gt_arr = data['gt']\n",
                "    spacing= data['spacing']\n",
                "\n",
                "    # Individual model metrics\n",
                "    for model_name, pred in masks.items():\n",
                "        tracker.add(\n",
                "            model=model_name, timepoint=tp,\n",
                "            pred=pred, gt=gt_arr, spacing=spacing\n",
                "        )\n",
                "\n",
                "    # Oracle weighted\n",
                "    wt_ensemble = weighted_avg(masks, gt_arr)\n",
                "    tracker.add(model='weighted_oracle', timepoint=tp,\n",
                "                pred=wt_ensemble, gt=gt_arr, spacing=spacing)\n",
                "\n",
                "    # Other strategies\n",
                "    for name, fn in zip(strategy_names, strategy_fns):\n",
                "        try:\n",
                "            ensemble_pred = fn(masks)\n",
                "        except Exception as e:\n",
                "            print(f'  {name} failed for {tp}: {e}')\n",
                "            continue\n",
                "        tracker.add(model=name, timepoint=tp,\n",
                "                    pred=ensemble_pred, gt=gt_arr, spacing=spacing)\n",
                "        save_nifti(ensemble_pred, data['affine'], OUT_DIR / f'{name}_{tp}.nii.gz')\n",
                "\n",
                "print('\\n=== Per-model summary ===')\n",
                "print(tracker.summary().to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚îÄ‚îÄ Pairwise agreement matrix (baseline) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "import seaborn as sns\n",
                "\n",
                "masks_bl = all_results['baseline']['masks']\n",
                "agreement_df = pairwise_dice_matrix(masks_bl)\n",
                "print('Pairwise Dice between models (baseline):')\n",
                "print(agreement_df.round(3))\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(6, 5))\n",
                "sns.heatmap(agreement_df, annot=True, fmt='.3f', cmap='YlOrRd', vmin=0, vmax=1, ax=ax,\n",
                "            linewidths=0.5, square=True)\n",
                "ax.set_title('Inter-Model Agreement (Dice) ‚Äì Baseline', fontsize=13, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUT_DIR / 'pairwise_dice_heatmap.png', dpi=120, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚îÄ‚îÄ Visualise ensemble results (baseline) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "t1c_arr, _, _ = load_nifti(brats_paths['baseline']['t1c'])\n",
                "gt_arr, _, _  = load_nifti(mask_paths['baseline'])\n",
                "\n",
                "ensemble_preds = {}\n",
                "for name in ['majority_vote', 'union', 'intersection', 'staple']:\n",
                "    p = OUT_DIR / f'{name}_baseline.nii.gz'\n",
                "    if p.exists():\n",
                "        arr, _, _ = load_nifti(str(p))\n",
                "        ensemble_preds[name] = arr\n",
                "\n",
                "if ensemble_preds:\n",
                "    fig = plot_model_comparison(mri=t1c_arr, predictions=ensemble_preds, gt=gt_arr)\n",
                "    plt.savefig(OUT_DIR / 'ensemble_comparison.png', dpi=120, bbox_inches='tight')\n",
                "    plt.show()\n",
                "\n",
                "# Summary bar chart\n",
                "summary = tracker.summary()\n",
                "fig = plot_benchmark_bar(summary.reset_index(), metric='dice', title='Dice by Strategy (mean over timepoints)')\n",
                "plt.savefig(OUT_DIR / 'ensemble_dice_bar.png', dpi=120, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "tracker.to_dataframe().to_csv(OUT_DIR / 'ensemble_metrics.csv', index=False)\n",
                "print('Saved: outputs/05_ensemble/ensemble_metrics.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚îÄ‚îÄ Agreement score for chosen ensemble ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "best_ensemble_path = OUT_DIR / 'majority_vote_baseline.nii.gz'\n",
                "if best_ensemble_path.exists():\n",
                "    ensemble_arr, _, _ = load_nifti(str(best_ensemble_path))\n",
                "    agreement = agreement_score(masks_bl, ensemble_arr)\n",
                "    print('=== Agreement Score (baseline) ===')\n",
                "    for k, v in agreement.items():\n",
                "        print(f'  {k}: {v}')\n",
                "\n",
                "    # Clinical flags\n",
                "    mean_ag = agreement['mean_agreement']\n",
                "    if mean_ag >= 0.90:\n",
                "        flag = '‚úÖ HIGH ‚Äì auto-report'\n",
                "    elif mean_ag >= 0.75:\n",
                "        flag = '‚ö†Ô∏è  MODERATE ‚Äì flag for review'\n",
                "    else:\n",
                "        flag = 'üî¥ LOW ‚Äì require manual check'\n",
                "    print(f'\\nAgreement flag: {flag}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìã Ensemble Strategy Recommendations\n",
                "\n",
                "| Strategy | Mean Dice | Agreement Score | Recommendation |\n",
                "|----------|-----------|-----------------|----------------|\n",
                "| Majority vote | _score_ | _score_ | ‚úÖ **Default choice** |\n",
                "| STAPLE | _score_ | _score_ | Consider when model calibration varies |\n",
                "| Union | _score_ | _score_ | High sensitivity, noisy |\n",
                "| Intersection | _score_ | _score_ | High specificity, misses edges |\n",
                "| Weighted (oracle) | _score_ | _score_ | Upper bound ‚Äì not usable in production |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}